{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(10, 60000)\n",
      "(784, 0)\n",
      "(10, 0)\n"
     ]
    }
   ],
   "source": [
    "# Read Fashion MNIST dataset\n",
    "\n",
    "import util_mnist_reader as mnist_reader\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "# Your code goes here . . .\n",
    "digits = 10\n",
    "examples = y_train.shape[0]\n",
    "\n",
    "y = y_train.reshape(1, examples)\n",
    "\n",
    "#np.eye gives you an array with all 0s and a 1 down the main diagonal\n",
    "#but if we index it with y(the correct label) as int it will index the 1\n",
    "#at the correction location instead of the main diagonal\n",
    "Y_new = np.eye(digits)[y.astype('int')]\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "\n",
    "m = 60000\n",
    "\n",
    "X_train, X_test = X_train[:m].T, X_test[m:].T\n",
    "y_train, y_test = Y_new[:,:m], Y_new[:,m:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def compute_loss(Y, Y_guess):\n",
    "\n",
    "    total_loss = np.sum(np.multiply(Y, np.log(Y_guess)))\n",
    "    loss = -(1/Y.shape[1]) * total_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#So we now have our data partitioned between training and testing\n",
    "#X matrix is the 60,000 examples for training and 10,000 for testing\n",
    "#Pixel value is 0-255 depending on darkness\n",
    "#Y matrix has the classification for each item ranging from 0-9 and labels are 1-10 so y+1 is the label\n",
    "#divide all values by 255 to get them on a 0-1 sacle\n",
    "X_train = X_train /255\n",
    "\n",
    "plt.imshow(X_train[:,1].reshape(28,28))\n",
    "plt.show()\n",
    "print(y_train[:,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss:  9.340384966728427\n",
      "Epoch 100 loss:  1.9361937817422876\n",
      "Epoch 200 loss:  1.4004166063303842\n",
      "Epoch 300 loss:  1.1773091450253343\n",
      "Epoch 400 loss:  1.0524416568083896\n",
      "Number Correct:  39870  Number Wrong:  20130  Accuracy:  0.6645\n",
      "Final loss: 0.9744780451917289\n"
     ]
    }
   ],
   "source": [
    "iterations    = 500\n",
    "learning_rate = .1\n",
    "\n",
    "#initialize weights and bias\n",
    "W1 = np.random.randn(64, X_train.shape[0])\n",
    "b1 = np.zeros((64, 1))\n",
    "W2 = np.random.randn(digits, 64)\n",
    "b2 = np.zeros((digits, 1))\n",
    "\n",
    "for i in range(iterations):\n",
    "    \n",
    "    #make a prediction\n",
    "    Z1 = np.matmul(W1,X_train) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "    #compute loss by comparing predictions to actual answers\n",
    "    loss = compute_loss(y_train, A2)       \n",
    "\n",
    "    #update weights and bias\n",
    "    dZ2 = A2-y_train\n",
    "    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.matmul(dZ1, X_train.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Epoch\", i, \"loss: \", loss)\n",
    "\n",
    "#make a prediction\n",
    "Z1 = np.matmul(W1,X_train) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2,A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "#find out what our guess is by finding max probable answer is\n",
    "answers = A2.T\n",
    "real_answers = y_train.T\n",
    "final_guess = []\n",
    "final_answer = []\n",
    "\n",
    "cur_max = answers[0][0]\n",
    "cur_index = 0\n",
    "for i in range(len(answers)):\n",
    "\n",
    "    cur_max = answers[i][0]\n",
    "    cur_index = 0  \n",
    "    for j in range(len(answers[1])):\n",
    "        if answers[i][j] > cur_max:\n",
    "            cur_max = answers[i][j]\n",
    "            cur_index = j\n",
    "        if real_answers[i][j] == 1:\n",
    "            final_answer.append(j)\n",
    "    final_guess.append(cur_index)\n",
    "\n",
    "number_correct = 0\n",
    "number_wrong = 0\n",
    "for i in range(len(final_guess)):\n",
    "    if final_guess[i] == final_answer[i]:\n",
    "        number_correct += 1\n",
    "    else:\n",
    "        number_wrong += 1\n",
    "total_number = number_correct + number_wrong\n",
    "accuracy = number_correct / total_number\n",
    "print(\"Number Correct: \", number_correct, \" Number Wrong: \", number_wrong, \" Accuracy: \",accuracy)\n",
    "print(\"Final loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.5759 - acc: 0.7926\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.3988 - acc: 0.8552\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3595 - acc: 0.8681\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3363 - acc: 0.8756\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3153 - acc: 0.8827\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3038 - acc: 0.8867\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2910 - acc: 0.8910\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2804 - acc: 0.8956\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2737 - acc: 0.8989\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2645 - acc: 0.9007\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2559 - acc: 0.9052\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2488 - acc: 0.9058\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2394 - acc: 0.9110\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2368 - acc: 0.9121\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2276 - acc: 0.9150\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2215 - acc: 0.9170\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2181 - acc: 0.9178\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2104 - acc: 0.9213\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2074 - acc: 0.9227\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2002 - acc: 0.9243\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1967 - acc: 0.9260\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1939 - acc: 0.9274\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1873 - acc: 0.9297\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1830 - acc: 0.9312\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1785 - acc: 0.9338\n",
      "\n",
      "10000/10000 [==============================] - 1s 115us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3695673335015774, 0.8807]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#mult layer hidden net utilizing keras\n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "X_train = (X_train / 255) - 0.5\n",
    "X_test  = (X_test  / 255) - 0.5\n",
    "\n",
    "X_train = X_train.reshape((-1,784))\n",
    "X_test = X_test.reshape((-1,784))\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(784,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    to_categorical(y_train),\n",
    "    epochs=25,\n",
    "    batch_size=128,\n",
    ")\n",
    "print(\"\")\n",
    "model.evaluate(\n",
    "    X_test,\n",
    "    to_categorical(y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 38s 628us/step - loss: 0.5984 - acc: 0.7951 - val_loss: 0.4694 - val_acc: 0.8315\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 40s 675us/step - loss: 0.4212 - acc: 0.8527 - val_loss: 0.4178 - val_acc: 0.8538\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 41s 679us/step - loss: 0.3873 - acc: 0.8650 - val_loss: 0.4018 - val_acc: 0.8567\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 41s 676us/step - loss: 0.3644 - acc: 0.8734 - val_loss: 0.3838 - val_acc: 0.8665\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 41s 680us/step - loss: 0.3533 - acc: 0.8759 - val_loss: 0.3733 - val_acc: 0.8698\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 41s 681us/step - loss: 0.3381 - acc: 0.8815 - val_loss: 0.3580 - val_acc: 0.8756\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 41s 683us/step - loss: 0.3283 - acc: 0.8855 - val_loss: 0.3561 - val_acc: 0.8732\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 41s 678us/step - loss: 0.3181 - acc: 0.8881 - val_loss: 0.3483 - val_acc: 0.8752\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 42s 695us/step - loss: 0.3100 - acc: 0.8919 - val_loss: 0.3512 - val_acc: 0.8763\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 41s 676us/step - loss: 0.3028 - acc: 0.8935 - val_loss: 0.3331 - val_acc: 0.8822\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 40s 672us/step - loss: 0.2950 - acc: 0.8962 - val_loss: 0.3431 - val_acc: 0.8795\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 40s 671us/step - loss: 0.2898 - acc: 0.8981 - val_loss: 0.3283 - val_acc: 0.8852\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 40s 669us/step - loss: 0.2832 - acc: 0.9006 - val_loss: 0.3271 - val_acc: 0.8847\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 40s 667us/step - loss: 0.2774 - acc: 0.9019 - val_loss: 0.3228 - val_acc: 0.8893\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 40s 675us/step - loss: 0.2745 - acc: 0.9029 - val_loss: 0.3190 - val_acc: 0.8868\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 40s 674us/step - loss: 0.2677 - acc: 0.9055 - val_loss: 0.3182 - val_acc: 0.8897\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 40s 672us/step - loss: 0.2646 - acc: 0.9063 - val_loss: 0.3174 - val_acc: 0.8888\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 40s 670us/step - loss: 0.2602 - acc: 0.9091 - val_loss: 0.3209 - val_acc: 0.8872\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 40s 674us/step - loss: 0.2574 - acc: 0.9089 - val_loss: 0.3154 - val_acc: 0.8899\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 41s 675us/step - loss: 0.2532 - acc: 0.9110 - val_loss: 0.3168 - val_acc: 0.8891\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 41s 679us/step - loss: 0.2511 - acc: 0.9109 - val_loss: 0.3153 - val_acc: 0.8903\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 40s 673us/step - loss: 0.2467 - acc: 0.9127 - val_loss: 0.3113 - val_acc: 0.8906\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 40s 672us/step - loss: 0.2438 - acc: 0.9131 - val_loss: 0.3134 - val_acc: 0.8903\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 40s 667us/step - loss: 0.2409 - acc: 0.9141 - val_loss: 0.3136 - val_acc: 0.8919\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 41s 675us/step - loss: 0.2389 - acc: 0.9156 - val_loss: 0.3124 - val_acc: 0.8909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23282623f48>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "\n",
    "#convulationary keras net\n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "X_train = (X_train / 255) - 0.5\n",
    "X_test  = (X_test  / 255) - 0.5\n",
    "\n",
    "X_train = np.reshape(X_train, (60000,28,28))\n",
    "X_test = np.reshape(X_test, (10000,28,28))\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "num_filters = 12\n",
    "filter_size = 4\n",
    "pool_size   = 2\n",
    "batch_size  = 128\n",
    "epochs      = 25\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    'adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    to_categorical(y_train),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, to_categorical(y_test)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
